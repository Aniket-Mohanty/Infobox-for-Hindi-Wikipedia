{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from googletrans import Translator\n",
    "from transliterate import translit\n",
    "import pandas as pd\n",
    "import re\n",
    "import regex as re2\n",
    "from collections import defaultdict\n",
    "from time import sleep\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import wptools\n",
    "import json\n",
    "import requests\n",
    "from urllib.parse import  quote\n",
    "import mwparserfromhell as mwp\n",
    "import mwclient\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from polyglot.transliteration import Transliterator\n",
    "from polyglot.text import Text\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| [src] dictionary: 40897 types\n",
      "| [tgt] dictionary: 40897 types\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('/home/aniket/')\n",
    "\n",
    "from ilmulti.translator import from_pretrained\n",
    "translator = from_pretrained(tag='mm-all-iter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies=['translate.google.com','translate.google.co.kr']\n",
    "translator = Translator(service_urls=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparqlResults():\n",
    "    \n",
    "    def __init__(self,query_file):\n",
    "        \n",
    "        self.agent = 'AniketBot (User:Mohanty-Aniket)'\n",
    "        \n",
    "        with open(query_file, 'r') as file:\n",
    "            self.query = file.read()\n",
    "    \n",
    "    def _val_cols(self):\n",
    "        cols = list(self.df.columns.values)\n",
    "        tmp = []\n",
    "        for col in cols:\n",
    "            if(col.split('.')[-1] == 'value'):\n",
    "                tmp.append(col)\n",
    "        return tmp\n",
    "    \n",
    "    def change_item(self,newItem):\n",
    "        wikibase_item = newItem\n",
    "        query_id = '?query_id ' + '{wd:' + wikibase_item + '}'\n",
    "        self.query = re.sub(r'\\?query_id \\{.*\\}', query_id, self.query)    \n",
    "    \n",
    "    def results(self):\n",
    "        sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=self.agent)\n",
    "        sparql.setQuery(self.query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results = sparql.query().convert()\n",
    "        self.df = pd.json_normalize(results['results']['bindings'])\n",
    "        return self.df[self._val_cols()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparq_obj = sparqlResults('films.rq')\n",
    "sparq_obj.change_item('Q100801386')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparq_obj.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_cols_dict = {'query_idLabel.value':'name',\n",
    "                  'image.value':'image',\n",
    "                  'directorLabel.value':'director',\n",
    "                  'producer_nameLabel.value':'producer',\n",
    "                  'screenwriterLabel.value':'screenplay',\n",
    "                  'based_onnameLabel.value':'based_on', \n",
    "                  'castLabel.value':'starring', \n",
    "                  'composerLabel.value':'music', \n",
    "                  'dopLabel.value':'cinematography', \n",
    "                  'editorLabel.value':'editing', \n",
    "                  'productioncompanyLabel.value':'studio', \n",
    "                  'distributedbyLabel.value':'distributor', \n",
    "                  'publication.value':'released', \n",
    "                  'durationLabel.value':'runtime', \n",
    "                  'origincountryLabel.value':'country', \n",
    "                  'original_langLabel.value':'language', \n",
    "                  'costLabel.value':'budget', \n",
    "                  'boxofficeLabel.value':'gross'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_cols_dict = {\n",
    "   'query_idLabel.value':'name',\n",
    "    'image.value':'image',\n",
    "    'authorityLabel.value':'union',\n",
    "    'maxplayersLabel.value':'team',\n",
    "    'gendersLabel.value':'mgender',\n",
    "    'subclassLabel.value':'type',\n",
    "    'itemsusedLabel.value':'equipment',\n",
    "    'origincountryLabel.value':'region'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "# print(isEnglish('कोलकाता'))\n",
    "\n",
    "def is_date(text):\n",
    "    if ('{birth' in text.lower()) or ('{death' in text.lower()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_image(text):\n",
    "    if('.jpg' in text.lower() or '.png' in text.lower()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def Find_URL(string): \n",
    "    # findall() has been used  \n",
    "    # with valid conditions for urls in string \n",
    "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    if \"URL\" in string:\n",
    "        check = True\n",
    "    else:\n",
    "        check = False\n",
    "    url = re.findall(regex,string)  \n",
    "    if url or check:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def indic_translate(eng):\n",
    "    hi = []\n",
    "    for i in eng:\n",
    "        text=quote(i)\n",
    "        # text=quote('मनिश् जोए')\n",
    "        url='http://www.cfilt.iitb.ac.in/indicnlpweb/indicnlpws/translate/en/hi/{}/'.format(text)\n",
    "        ## Note the forward slash '/' at the end of the URL. It's should be there, but please live with it for now!\n",
    "\n",
    "        response = requests.get(url)\n",
    "        hi.append(response.json()['hi'])\n",
    "    return hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = defaultdict(list)\n",
    "\n",
    "for i in range(1457):\n",
    "    \n",
    "    with open('./stats/' + 'instance_' + str(i) + '.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    for key in data:\n",
    "        stats[key].extend(data[key])\n",
    "\n",
    "with open('./updated_parsed_data.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "dict_tmp = {}\n",
    "for key in data: #data from parsed_data.pkl\n",
    "    dict_tmp[data[key]['wikibase_item']] = data[key]['infobox']\n",
    "\n",
    "for key in stats:\n",
    "    for idx,item in enumerate(stats[key]):\n",
    "        wikibase_item = item['item']\n",
    "        if(wikibase_item in dict_tmp):\n",
    "            stats[key][idx]['infobox'] = dict_tmp[wikibase_item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances considered :- \n",
      "film\n",
      "short film\n",
      "animated feature film\n",
      "television film\n",
      "feature film\n",
      "silent short film\n",
      "animated film\n",
      "3D film\n",
      "cult film\n",
      "anthology film\n",
      "\n",
      "Total film pages:  4872\n",
      "Film no infobox:  1507\n",
      "\n",
      "\n",
      "-------\n",
      "\n",
      "Instances considered :- \n",
      "type of sport\n",
      "sport\n",
      "dog sport\n",
      "fictional sport\n",
      "individual sport\n",
      "winter sport\n",
      "mind sport\n",
      "\n",
      "Total sports pages:  63\n",
      "Sports no infobox:  45\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "noinfo_count = 0\n",
    "films_items_noinfobox = []\n",
    "films_with_infobox = []\n",
    "print('Instances considered :- ')\n",
    "for key in stats:\n",
    "    if('film' in key[-4:]):\n",
    "        print(key)\n",
    "        for val in stats[key]:\n",
    "            if(val['infobox'] == 0):\n",
    "                films_items_noinfobox.append(val['item'])\n",
    "                noinfo_count += 1\n",
    "            else:\n",
    "                films_with_infobox.append(val['item'])\n",
    "        total_count += len(stats[key])\n",
    "print('\\nTotal film pages: ',total_count)\n",
    "print('Film no infobox: ',noinfo_count)\n",
    "\n",
    "print('\\n\\n-------\\n')\n",
    "\n",
    "total_count = 0\n",
    "noinfo_count = 0\n",
    "sports_items_noinfobox = []\n",
    "print('Instances considered :- ')\n",
    "for key in stats:\n",
    "    if('sport' in key[-5:] and 'transport' not in key):\n",
    "        print(key)\n",
    "        for val in stats[key]:\n",
    "            if(val['infobox'] == 0):\n",
    "                sports_items_noinfobox.append(val['item'])\n",
    "                noinfo_count += 1\n",
    "        total_count += len(stats[key])\n",
    "print('\\nTotal sports pages: ',total_count)\n",
    "print('Sports no infobox: ',noinfo_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_infobox_from_wikidata(query_file, wikibase_item, translate = False):\n",
    "    \n",
    "    try:\n",
    "        sparq_obj = sparqlResults(query_file)\n",
    "        sparq_obj.change_item(wikibase_item)\n",
    "\n",
    "        results = sparq_obj.results()\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    infobox = []\n",
    "    print(results.columns.values)\n",
    "    for col in sports_cols_dict:\n",
    "        if(col in results.columns.values):\n",
    "            col_name = sports_cols_dict[col]\n",
    "            val = pd.unique(results[col])\n",
    "            hindi = []  \n",
    "            if(translate):\n",
    "                if(col_name == 'released'):\n",
    "                    val = [val[0][:-10]]\n",
    "                for vals in val:\n",
    "                    if isEnglish(vals) and not Find_URL(vals):\n",
    "                        translated = translator(vals, tgt_lang='hi', src_lang='en')\n",
    "                        translated = translated[0]['tgt']\n",
    "                        check = True\n",
    "        #                 if isEnglish(translated):\n",
    "        #                     check = False\n",
    "                        if check:\n",
    "                            hindi = hindi + [translated]\n",
    "                    else:\n",
    "                        if not Find_URL(vals):\n",
    "                            try:\n",
    "                                vals = translit(vals,reversed = True)\n",
    "                                translated = translator(vals, tgt_lang='hi', src_lang='en')\n",
    "                                translated = translated[0]['tgt']\n",
    "                                check = True\n",
    "        #                         if isEnglish(translated):\n",
    "        #                             check = False\n",
    "                                if check:\n",
    "                                    hindi = hindi + [translated]\n",
    "                            except:\n",
    "                                hindi.append(vals)\n",
    "                        else:\n",
    "                            hindi.append(vals)\n",
    "                info_str = col_name + ' = ' + ', '.join(hindi)\n",
    "            else:\n",
    "                hindi.append(', '.join(val))\n",
    "                info_str = col_name + ' = ' + hindi[0]\n",
    "\n",
    "            infobox.append(info_str)\n",
    "    return infobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_film_infobox(item_list, translate = False):\n",
    "    film_infoboxes = {}\n",
    "    errs = []\n",
    "    if(translate):\n",
    "        file = './sports.rq'\n",
    "    else:\n",
    "        file = './films_eng.rq'\n",
    "    for item in tqdm(item_list):\n",
    "        res = create_infobox_from_wikidata(file, item, translate)\n",
    "        if(res != []):\n",
    "            film_infoboxes[item] = res\n",
    "        else:\n",
    "            errs.append(item)\n",
    "    return film_infoboxes, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image.value' 'icon.value' 'pronounciation.value' 'query_idLabel.value'\n",
      " 'subclassLabel.value' 'practicedbyLabel.value' 'itemsusedLabel.value'\n",
      " 'authorityLabel.value' 'minplayersLabel.value' 'maxplayersLabel.value'\n",
      " 'instanceLabel.value' 'gendersLabel.value']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n"
     ]
    }
   ],
   "source": [
    "film_infoboxes,film_errs = create_all_film_infobox(['Q1734'], translate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1734': ['name = वालीबॉल',\n",
       "  'image = http://commons.wikimedia.org/wiki/Special:FilePath/Red%20dragons%20kwalificeren%20zich%20tegen%20grieken%20voor%20ek.jpg',\n",
       "  'union = फेडरेशन इंटरनेशनल डे वोलीबॉल',\n",
       "  'team = 12',\n",
       "  'mgender = महिलाओं का वॉलीबॉल, पुरुषों की वॉलीबॉल',\n",
       "  'type = टीम खेल, गेंद खेल',\n",
       "  'equipment = वॉलीबॉल, वॉलीबॉल कोर्ट']}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_infoboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('film_infoboxes_english_wikidata.pkl', 'wb') as handle:\n",
    "    pickle.dump(film_infoboxes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('film_infoboxes.pkl', 'wb') as handle:\n",
    "    pickle.dump(film_infoboxes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Terminator 2: Judgment Day',\n",
       " 'image': 'Terminator2poster.jpg',\n",
       " 'caption': 'Theatrical release poster',\n",
       " 'director': '[[James Cameron]]',\n",
       " 'producer': 'James Cameron',\n",
       " 'writer': '{{Plainlist|\\n* James Cameron\\n* [[William Wisher]]}}',\n",
       " 'starring': '{{Plainlist|\\n* [[Arnold Schwarzenegger]]\\n* [[Linda Hamilton]]\\n* [[Robert Patrick]]\\n|<!--These three actors are the only ones listed on the billing block; per [[Template:Infobox film]]. -->}}',\n",
       " 'music': '[[Brad Fiedel]]',\n",
       " 'cinematography': '[[Adam Greenberg (cinematographer)|Adam Greenberg]]',\n",
       " 'editing': '{{Plainlist|\\n* [[Conrad Buff]]\\n* [[Mark Goldblatt]]\\n* [[Richard A. Harris]]}}',\n",
       " 'studio': '{{Plainlist|\\n* [[Carolco Pictures]]\\n* [[Pacific Western Productions]]\\n* [[Lightstorm Entertainment]]\\n* [[StudioCanal|Le Studio Canal+ S.A.]]}}',\n",
       " 'distributor': '[[TriStar Pictures]]',\n",
       " 'released': '{{Film date|1991|7|1|Los Angeles|1991|7|3|United States}}',\n",
       " 'runtime': '137 minutes',\n",
       " 'country': 'United States',\n",
       " 'language': 'English',\n",
       " 'budget': '$94–102 million',\n",
       " 'gross': '$520.8 million'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_id = 'Q170564'\n",
    "titles = wptools.page(wikibase = entity_id, silent = True).get_wikidata()\n",
    "title_list = titles.data['title'].split('_')\n",
    "title = \" \".join(title_list)\n",
    "page = wptools.page(title, silent = True)\n",
    "page = page.get_parse()\n",
    "page.data['infobox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_infobox_from_english_wiki(page, translate = False):\n",
    "    key_en = list(page.data['infobox'].keys())\n",
    "    value_en = list(page.data['infobox'].values())\n",
    "    infobox = []\n",
    "\n",
    "    for ind in range(len(key_en)):\n",
    "        flag = 0\n",
    "#         if('flatlist' in value_en[ind]):\n",
    "        if Find_URL(value_en[ind]):\n",
    "            continue\n",
    "\n",
    "        value_en[ind] = value_en[ind].strip('{}')\n",
    "        value_en[ind] = re.sub(r'flatlist','',value_en[ind])\n",
    "        value_en[ind] = re.sub(r'Unbulleted list','',value_en[ind])\n",
    "        value_en[ind] = re.sub(r'Plainlist','',value_en[ind])\n",
    "        value_en[ind] = value_en[ind].strip('*')\n",
    "#         print(value_en[ind])\n",
    "        value_en[ind] = re.sub(r'\\|',' ',value_en[ind])\n",
    "        value_en[ind] = re.sub('[^0-9a-zA-Z ,.\\.,.-]+','',value_en[ind])\n",
    "#         print(value_en[ind])\n",
    "        if not Find_URL(value_en[ind]) and not is_date(value_en[ind]):\n",
    "#             print(value_en[ind])\n",
    "            vals = mwp.parse(value_en[ind]).strip_code().replace('*','')\n",
    "        \n",
    "        vals = value_en[ind].strip()\n",
    "        hindi = []\n",
    "        if(translate and vals):\n",
    "            if(key_en[ind] in ['image', 'imagesize']):\n",
    "                infobox.extend([key_en[ind]+\" = \"+value_en[ind]])\n",
    "                continue\n",
    "            if not is_date(vals) and not is_image(vals):\n",
    "                if isEnglish(vals) and not Find_URL(vals):\n",
    "                    translated = translator(vals, tgt_lang='hi', src_lang='en')\n",
    "#                     print(translated,'val: ',vals)\n",
    "                    translated = translated[0]['tgt']\n",
    "                    hindi.append(translated)\n",
    "                else:\n",
    "                    if not Find_URL(vals):\n",
    "                        try:\n",
    "                            vals = translit(vals,reversed = True)\n",
    "                            translated = translator(vals, tgt_lang='hi', src_lang='en')\n",
    "                            translated = translated[0]['tgt']\n",
    "                            hindi.append(translated)\n",
    "                        except:\n",
    "                            hindi.append(vals)\n",
    "                    else:\n",
    "                        hindi.append(vals)\n",
    "            else:\n",
    "                hindi.append(vals)\n",
    "        else:\n",
    "            hindi.append(vals)\n",
    "        infobox.extend([key_en[ind]+\" = \"+hindi[0]])\n",
    "    return infobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_film_from_english(item_list, translate = False):\n",
    "    no_infobox = []\n",
    "    errs = []\n",
    "    infoboxes = {}\n",
    "    cnt = 0\n",
    "    for entity_id in tqdm(item_list):\n",
    "        try:\n",
    "            titles = wptools.page(wikibase = entity_id, silent = True).get_wikidata()\n",
    "            title_list = titles.data['title'].split('_')\n",
    "            title = \" \".join(title_list)\n",
    "            page = wptools.page(title, silent = True)\n",
    "            page = page.get_parse()\n",
    "            if(page.data['infobox']):\n",
    "    #             print('infobox',page.data['infobox'])\n",
    "                infoboxes[entity_id] = create_infobox_from_english_wiki(page, translate)\n",
    "                cnt += 1\n",
    "            else:\n",
    "                no_infobox.append(entity_id)\n",
    "        except:\n",
    "            errs.append(entity_id)\n",
    "        print(cnt)\n",
    "    return infoboxes, no_infobox, errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "film_infoboxes_from_english, film_no_english_infobox, film_errs_from_english = create_all_film_from_english(['Q1734'], translate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('film_infoboxes_gt_translated.pkl', 'wb') as handle:\n",
    "#     pickle.dump(film_infoboxes_from_english, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_infobox_string(infobox_list,template):\n",
    "#     template = 'writer'\n",
    "    infobox_str = '{{Infobox ' + template + '\\n'\n",
    "    for line in infobox_list:\n",
    "        infobox_str += '|' + line + '\\n'\n",
    "    infobox_str += '}}'\n",
    "    return infobox_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_to_sandbox(infobox_str,input_page,credentials):\n",
    "    with open(credentials,'r') as cred:\n",
    "        for line in cred:\n",
    "            if(line[:4] == 'user'): user = line.split('=')[-1].strip('\\n')\n",
    "            if(line[:8] == 'password'): password = line.split('=')[-1]\n",
    "    site = mwclient.Site('hi.wikipedia.org')\n",
    "    site.login(user, password)\n",
    "    old_page = site.Pages[input_page]\n",
    "    old_text = old_page.text()\n",
    "    old_text = re2.sub(r'(?=\\{Infobox)(\\{([^{}]|(?1))*\\})','',old_text,flags = re.S)\n",
    "    old_text = re2.sub(r'(?=\\{ज्ञानसन्दूक)(\\{([^{}]|(?1))*\\})','',old_text,flags = re.S)\n",
    "#     print(old_page.text())\n",
    "    page = site.Pages['User:Mohanty-Aniket/प्रयोगपृष्ठ']\n",
    "#     page = site.Pages['User:Mohanty-Aniket/sandbox']\n",
    "    text = infobox_str\n",
    "    page.save(text + '\\n' + old_text,summary='trying wikidata-infobox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "infobox_str = create_infobox_string(film_infoboxes['Q1734'],'film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish_to_sandbox(infobox_str,'Baahubali:_The_Beginning','credentials.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{Infobox film\n",
      "|name = वालीबॉल\n",
      "|image = http://commons.wikimedia.org/wiki/Special:FilePath/Red%20dragons%20kwalificeren%20zich%20tegen%20grieken%20voor%20ek.jpg\n",
      "|union = फेडरेशन इंटरनेशनल डे वोलीबॉल\n",
      "|team = 12\n",
      "|mgender = महिलाओं का वॉलीबॉल, पुरुषों की वॉलीबॉल\n",
      "|type = टीम खेल, गेंद खेल\n",
      "|equipment = वॉलीबॉल, वॉलीबॉल कोर्ट\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "print(infobox_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('film_infoboxes.pkl', 'rb') as handle:\n",
    "    wikidat_info = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('film_infoboxes_gt_translated.pkl', 'rb') as handle:\n",
    "    trans_info = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pages = [list(wikidat_info.keys()),list(trans_info.keys())]\n",
    "res = set(valid_pages[0]).intersection(*valid_pages)\n",
    "valid_pages = list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q190908', 'Q23647131', 'Q62023603', 'Q47703', 'Q3765055']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pages[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "सात\n",
      "{{Infobox film\n",
      "|name = सात\n",
      "|image = Seven movie poster.jpg\n",
      "|caption = थियेटर रिलीज पोस्टर\n",
      "|director = डेविड फंचर\n",
      "|producers = जुब्ल अरनल्ड कोपेल्सन फिलिस कार्लाइल\n",
      "|writer = एंड्रयू केविन वॉकर\n",
      "|starring = ubl Brad Pitt Morgan riman Gwyneth Paltro John McGinley ------------\n",
      "|music = हावर्ड शॉयर\n",
      "|cinematography = डेरियस खोंडजी\n",
      "|editing = रिचर्ड फ्रांसिस-ब्रूस\n",
      "|studio = जुब्ल चेकी गोरी चित्र जूनो पिक्स\n",
      "|distributor = नई पंक्ति सिनेमा\n",
      "|released = फिल्म की तारीख 1995 09 15 एलिस टुली हॉल 1995 09 22 अमेरिका\n",
      "|runtime = 127 मिनट\n",
      "|country = अमेरिका\n",
      "|language = अंग्रेजी\n",
      "|budget = 33 करोड़\n",
      "|gross = 327.3 करोड़\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "for i in [0]:\n",
    "    title = trans_info[valid_pages[i]][0].split('=')[-1].strip()\n",
    "#     print(title)\n",
    "#     if(title == 'द मार्शियन'):\n",
    "    title = '_'.join(title.split())\n",
    "    print(title)\n",
    "    infobox_str = create_infobox_string(trans_info[valid_pages[i]],'film')\n",
    "    print(infobox_str)\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_to_sandbox(infobox_str,'वालीबॉल','credentials.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ire",
   "language": "python",
   "name": "ire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
